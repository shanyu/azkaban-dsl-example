hadoop {
  buildPath "azkaban" // Declare the output folder for the compiled Azkaban files
  cleanPath true // Automatically clean up the output folder before each new build

  // Declare an Azkaban .properties file that sets some Azkaban properties for your jobs
  propertyFile('common') {
    set properties: [
      'failure.emails': lookupDef('notifyEmail')
      //'user.to.proxy': lookupDef('userToProxy')
    ]
  }
}

// Generic with spark-submit job
hadoopShellJob('sparkSubmitJob') {
  // must use single quote here to replace variables at runtime from properties
  uses 'spark-submit --class ${class} --master ${master} --driver-memory ${driver.memory} --executor-memory ${executor.memory} --executor-cores ${executor.cores} --num-executors ${num.executors} ${execute.jar} ${params}'
  set properties: [
    'class': 'com.microsoft.spark.WordCount',
    'master': 'yarn-cluster',
    'driver.memory': '512m',
    'executor.memory': '512m',
    'executor.cores': '1',
    'num.executors': 2,
    'execute.jar': 'lib/azkaban-dsl-example.jar',
    'params': ""
  ]
}

